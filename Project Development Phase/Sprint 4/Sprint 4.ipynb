{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22f0d2db",
   "metadata": {},
   "source": [
    "# Sprint 4\n",
    "### Mekala Bhargav\n",
    "### N Pavan\n",
    "### Munjuru Bharadwaja\n",
    "### Nariboyina Pavan Sai\n",
    "\n",
    "\n",
    "# Detection of Fire using Live video capturing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab6dae30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 436 images belonging to 2 classes.\n",
      "Found 121 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 111s 7s/step - loss: 0.6244 - accuracy: 0.6674 - val_loss: 0.6684 - val_accuracy: 0.5275\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 65s 5s/step - loss: 0.4718 - accuracy: 0.8073 - val_loss: 0.3878 - val_accuracy: 0.8280\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 49s 4s/step - loss: 0.3256 - accuracy: 0.8647 - val_loss: 0.2778 - val_accuracy: 0.8693\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 47s 3s/step - loss: 0.1839 - accuracy: 0.9220 - val_loss: 0.1562 - val_accuracy: 0.9243\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 49s 4s/step - loss: 0.2081 - accuracy: 0.9312 - val_loss: 0.1558 - val_accuracy: 0.9381\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 50s 4s/step - loss: 0.1510 - accuracy: 0.9358 - val_loss: 0.1341 - val_accuracy: 0.9495\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 47s 3s/step - loss: 0.1499 - accuracy: 0.9450 - val_loss: 0.1447 - val_accuracy: 0.9427\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 49s 4s/step - loss: 0.1558 - accuracy: 0.9381 - val_loss: 0.1643 - val_accuracy: 0.9220\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 47s 4s/step - loss: 0.1717 - accuracy: 0.9289 - val_loss: 0.1366 - val_accuracy: 0.9587\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 51s 4s/step - loss: 0.1481 - accuracy: 0.9495 - val_loss: 0.1766 - val_accuracy: 0.9220\n",
      "14/14 [==============================] - 23s 2s/step\n",
      "436\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "\n",
    "\n",
    "import keras \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,rotation_range=180,zoom_range=0.2,horizontal_flip=True)\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "x_train=train_datagen.flow_from_directory(r'C:\\Users\\green\\Downloads\\Dataset\\Dataset\\train_set',target_size=(128,128),batch_size=32,class_mode='binary')\n",
    "x_test=test_datagen.flow_from_directory(r'C:\\Users\\green\\Downloads\\Dataset\\Dataset\\test_set',target_size=(128,128),batch_size=32,class_mode='binary')\n",
    "\n",
    "train=ImageDataGenerator(rescale=1./255,\n",
    "                                 shear_range=0.2,\n",
    "                                 rotation_range=180,\n",
    "                                 zoom_range=0.2,\n",
    "                                 horizontal_flip=True)\n",
    "train = ImageDataGenerator(rescale=1/255)\n",
    "test = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x_train.class_indices\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "#to add layer import Dense\n",
    "from keras.layers import Dense\n",
    "#to create convolution kernel import convolution2D\n",
    "from keras.layers import Convolution2D\n",
    "#import Maxpooling layer\n",
    "from keras.layers import MaxPooling2D\n",
    "#import flatten layer\n",
    "from keras.layers import Flatten\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Convolution2D(32,(3,3),input_shape=(128,128,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Convolution2D(32,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Convolution2D(32,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Convolution2D(32,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(150,activation='relu'))\n",
    "\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = \"adam\",\n",
    "              metrics = [\"accuracy\"])\n",
    "\n",
    "\n",
    "\n",
    "r = model.fit(x_train, epochs = 10, validation_data = x_train)\n",
    "\n",
    "\n",
    "\n",
    "predictions = model.predict(x_train)\n",
    "predictions = np.round(predictions)\n",
    "\n",
    "\n",
    "\n",
    "predictions\n",
    "\n",
    "\n",
    "print(len(predictions))\n",
    "\n",
    "\n",
    "\n",
    "#import load_model from keras.model\n",
    "from keras.models import load_model\n",
    "#import image class from keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "#import numpy\n",
    "import numpy as np\n",
    "#import cv2\n",
    "import cv2\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "model.save(\"forest1.h5\")\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99245567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 11s 3s/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "model=load_model(\"forest1.h5\")\n",
    "img=image.load_img(r\"C:\\Users\\green\\Downloads\\Dataset\\Dataset\\train_set\\with fire\\with fire.jpeg\")\n",
    "x=image.img_to_array(img)\n",
    "x=np.expand_dims(x,axis=0)\n",
    "pred=model.predict(x_test) \n",
    "classes_x=np.argmax(pred,axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886c0743",
   "metadata": {},
   "source": [
    "# Capturing using Video camera and Detection of fire which sends alert message from twilio account to provided phone number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e152abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 7s 2s/step\n",
      "4/4 [==============================] - 7s 2s/step\n",
      "No Danger\n",
      "4/4 [==============================] - 7s 1s/step\n",
      "4/4 [==============================] - 7s 2s/step\n",
      "No Danger\n",
      "4/4 [==============================] - 7s 2s/step\n",
      "4/4 [==============================] - 7s 1s/step\n",
      "No Danger\n",
      "4/4 [==============================] - 7s 2s/step\n",
      "4/4 [==============================] - 7s 1s/step\n",
      "No Danger\n",
      "4/4 [==============================] - 7s 2s/step\n",
      "4/4 [==============================] - 7s 2s/step\n",
      "No Danger\n",
      "4/4 [==============================] - 7s 2s/step\n",
      "4/4 [==============================] - 7s 1s/step\n",
      "No Danger\n",
      "4/4 [==============================] - 7s 2s/step\n",
      "4/4 [==============================] - 7s 2s/step\n",
      "No Danger\n",
      "4/4 [==============================] - 7s 2s/step\n",
      "4/4 [==============================] - 7s 2s/step\n",
      "No Danger\n",
      "4/4 [==============================] - 7s 1s/step\n",
      "4/4 [==============================] - 7s 2s/step\n",
      "No Danger\n",
      "4/4 [==============================] - 7s 2s/step\n",
      "4/4 [==============================] - 7s 2s/step\n",
      "No Danger\n",
      "4/4 [==============================] - 8s 2s/step\n",
      "4/4 [==============================] - 7s 2s/step\n",
      "No Danger\n",
      "4/4 [==============================] - 7s 2s/step\n",
      "4/4 [==============================] - 7s 2s/step\n",
      "No Danger\n",
      "4/4 [==============================] - 7s 2s/step\n",
      "4/4 [==============================] - 8s 2s/step\n",
      "No Danger\n",
      "4/4 [==============================] - 8s 2s/step\n",
      "4/4 [==============================] - 7s 2s/step\n",
      "No Danger\n",
      "4/4 [==============================] - 7s 2s/step\n",
      "4/4 [==============================] - 7s 2s/step\n",
      "No Danger\n",
      "4/4 [==============================] - 7s 2s/step\n",
      "4/4 [==============================] - 7s 2s/step\n",
      "No Danger\n",
      "2/4 [==============>...............] - ETA: 2s"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import load_model\n",
    "from twilio.rest import Client\n",
    "from playsound import playsound\n",
    "model = load_model(r\"forest1.h5\")\n",
    "video=cv2.VideoCapture(0)\n",
    "name=['forest','with fire']\n",
    "\n",
    "while(1):\n",
    "    success,frame=video.read()\n",
    "    cv2.imwrite(r\"C:\\Users\\green\\Downloads\\Dataset\\Dataset\\train_set\\with fire\\with fire.jpeg\",frame)\n",
    "    img=image.load_img(r\"C:\\Users\\green\\Downloads\\Dataset\\Dataset\\train_set\\with fire\\with fire.jpeg\",target_size=(128,128))\n",
    "    x=image.img_to_array(img)\n",
    "    x=np.expand_dims(x,axis=0)\n",
    "    pred=model.predict(x_test)\n",
    "    classes_x=np.argmax(pred,axis=1)\n",
    "    p=pred[0]\n",
    "    \n",
    "    pred=model.predict(x_test)\n",
    "    classes_x=np.argmax(pred,axis=1)\n",
    "    if pred[0]==1:\n",
    "        \n",
    "        account_sid='AC8d01fbf54781ba3b4d1e493f1e480f2f'\n",
    "        auth_token='ea25472d4c75ba8dd0f67f51619b62cb'\n",
    "        client=Client(account_sid,auth_token)\n",
    "        message=client.messages\\\n",
    "        .create(\n",
    "        body='Forest fire is detected, stay alert',\n",
    "        from_='+13854387861',\n",
    "        to='+919550630271')\n",
    "        print(message.sid)\n",
    "        print(\"Fire detected\")\n",
    "        print(\"SMS sent\")\n",
    "        playsound(r\"C:\\Users\\green\\Downloads\\Sab Tera.mp3\")\n",
    "    else:\n",
    "        print(\"No Danger\")\n",
    "    cv2.imshow(r\"C:\\Users\\green\\Downloads\\Dataset\\Dataset\\train_set\\with fire\\with fire.jpeg\",frame)\n",
    "    if cv2.waitKey(1) & 0xFF ==ord(\"a\"):\n",
    "        break\n",
    "        \n",
    "video.release()\n",
    "cv2=destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37d23c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
